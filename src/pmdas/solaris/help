#
# Copyright (c) 2000-2004 Silicon Graphics, Inc.  All Rights Reserved.
# 
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
# 
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
# or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
# for more details.
# 
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
#
# Solaris PMDA help file in the ASCII format
#
# lines beginning with a # are ignored
# lines beginning @ introduce a new entry of the form
#  @ metric_name oneline-text
#  help test goes
#  here over multiple lines
#  ...
#
# the metric_name is decoded against the default PMNS -- as a special case,
# a name of the form NNN.MM (for numeric NNN and MM) is interpreted as an
# instance domain identification, and the text describes the instance domain
#
# blank lines before the @ line are ignored
#

@ kernel.all.cpu.idle TODO
@ kernel.all.cpu.user TODO
@ kernel.all.cpu.sys TODO
@ kernel.all.cpu.wait.total TODO
@ kernel.percpu.cpu.user TODO
@ kernel.percpu.cpu.idle TODO
@ kernel.percpu.cpu.sys TODO
@ kernel.percpu.cpu.wait.total TODO
@ disk.all.read TODO
@ disk.all.write TODO
@ disk.all.total TODO
@ disk.all.read_bytes TODO
@ disk.all.write_bytes TODO
@ disk.all.total_bytes TODO
@ disk.dev.read TODO
@ disk.dev.write TODO
@ disk.dev.total TODO
@ disk.dev.read_bytes TODO
@ disk.dev.write_bytes TODO
@ disk.dev.total_bytes TODO
# #@ mem.page_faults TODO
# #@ mem.available TODO
# #@ mem.committed_bytes TODO
# #@ mem.pool.paged_bytes TODO
# #@ mem.pool.non_paged_bytes TODO
# #@ mem.cache.read_ahead TODO
# #@ mem.cache.lazy_writes TODO
# #@ mem.cache.lazy_write_pages TODO
# #@ mem.cache.mdl.read TODO
# #@ mem.cache.mdl.sync_read TODO
# #@ mem.cache.mdl.async_read TODO
@ network.interface.mtu Maximum Transmission Unit of a network interface
Maximum Transmision Unit is the largest size of IP datagram which can be
transferred over the data link.
@ network.interface.in.bytes Number of bytes received by a network interface
@ network.interface.in.errors Number of receive errors per network interface
Number of receive errors per network interface. The errors counted towards
this metric are: IP header errors, packets larger then the link MTU, packets
delivered to the unknown address, packets sent to the unknown IP protocol,
truncated packets, packets discarded due to not having a route for
the destination.
@ network.interface.in.drops Number of packets droped by a network interface
Number of packets discared due to lack of space during the input processing.
@ network.interface.in.delivers Number of packets delivered to ULPs
Number of packets delivered for further processing by the upper-layer
protocols.
@ network.interface.in.bcasts Number of broadcast packets received by a network interface
@ network.interface.in.packets Number of IP packets received by a network interface
@ network.interface.in.mcasts Number of multicast packets received by a network interface
@ network.interface.out.packets Number of packets sent by a network interface
@ network.interface.out.bytes Number of bytes sent by a network interface
@ network.interface.out.errors Number of send errors per network interface
@ network.interface.out.bcasts Number of broadcast packets sent by a network interface
@ network.interface.out.mcasts Number of multicast packets sent by a network interface
@ network.interface.out.drops Number of packets discared by a network interface
Number of packets discared due to lack of space during the output processing.
@ network.udp.ipackets Number of UDP packets received
@ network.udp.opackets Number of UDP packets sent
@ network.udp.ierrors Number of receive errors in UDP processing
@ network.udp.oerrors Number of send erros in UDP processing
@ network.udp.noports Number of UDP packets received on unknown UDP port
Number of UDP packets received for which here is no port can be found.
This counter is reported on the per-interface basis and aggregated by the PMDA.

@ network.udp.overflows Number of UDP packets droped due to queue overflow
Number of UDP packets droped due to queue overflow. 
This counter is reported on the per-interface basis and aggregated by the PMDA.

# #@ network.interface.total.packets TODO
# #@ network.interface.total.bytes TODO

@zpool.capacity	Total capacity of a zpool in bytes
@zpool.used Total space used on a pool
@zpool.checksum_errors Number of checksum errors per zpool
@zpool.self_healed Number of bytes healed
@zpool.in.bytes	Counter of bytes read from a zpool
@zpool.out.bytes Counter of bytes written to a zpool
@zpool.in.ops Counter of reads per zpool
@zpool.out.ops Counter of writes per zpool
@zpool.in.errors Counter of read errors per zpool
@zpool.out.errors Counter of write errors per zpool
@zpool.state Current state of zpool
@zpool.state_int vs_aux << 8 | vs_state

@zfs.available Amount of space available to the dataset
The amount of space available to the dataset (a filesystem, 
a snapshot or a volume) and all its children. This is usually
the amount of space available in the zpool which houses the
dataset.

@zfs.used.total Amount of space used by the dataset and its children
The amount of space consumed by the filesystem, snapshot or
volume and all its children. This amount does not include
any reservation made by the dataset itself but do include
the reservation of the children.

@zfs.used.byme Amount of space used by the dataset itself.
This amount exclude any space used by the children of this dataset
or any of its snapshots.

@zfs.used.bysnapshots Amount of space used by the snapshots of the dataset
The amount of space consumed by the snapshots of this dataset.

@zfs.used.bychildren Amount of space used by decendents of the dataset
The amount of space consumed by all the decendants of this dataset.

@zfs.quota Maximum amount of space a dataset can use
Quotas are used to restrict the growth of the datasets. If
the quota is set to 0 then the size of the dataset is limited only
by the size of the pool which houses this dataset.

@zfs.reservation Minimum amount of space guaranteed to a dataset
The amount of space which dataset and its decendents are guaranteed
to be available for them to use. This amount of taken off the quota
of the parent of the dataset.

@zfs.compression Compression ratio of the dataset
Compression ratio is expressed as multiplier. To estimate how much data
will be used by the uncompressed data multiply the amount of space used
by the dataset by the compression ratio.

@zfs.copies Number of redundant copies of data
The number of redundant copies does not include any copies made as
part of the pool redundancy.

@zfs.recordsize Recommendend block size for files in filesystems
By using recommended block size applications which deal with fixed size
records can improve I/O performance.

@zfs.used.byrefreservation Space used by refreservation
The amount of space used by a refreservation set on this
filesystem,  which would be freed if the refreservation was
removed.

@zfs.refreservation Minimum amount of space guaranteed to a filesystem
The minimum amount of space guaranteed to a dataset, not
including its descendents. Unlike reservation refreservation is
counted towards the total used space of a dataset.

@zfs.refquota Amount of space a filesystem can consume
The hard limit on the amount of space a filesystem but not its descendants
can consume from the pool.

@zfs.referenced Amount of space referenced by the filesystem
The amount of data that is accessible by  the filesystem. The data
may be shared with other datasets in the pool.

@zfs.nsnapshots Number of snapshots in the filesystem

@zfs.snapshot.compression Compression ratio of the data in the snapshot
Compression ratio is expressed as multiplier. To estimate how much data
will be used by the uncompressed data multiply the amount of space used
by the snapshot by the compression ratio.

@zfs.snapshot.used Amount of space used by the snapshot

@zfs.snapshot.referenced Amount of space referenced by the snapshot
The amount of data that is accessible by  the snapshot. The data
may be shared with other datasets in the filesystem.


@zpool.perdisk.state Current state per disk in zpool
@zpool.perdisk.state_int vs_aux << 8 | vs_state
@zpool.perdisk.checksum_errors Number of checksum errors per disk in zpool
@zpool.perdisk.self_healed Number of bytes healed per disk in zpool
@zpool.perdisk.in.errors Counter of read errors per disk in zpool
@zpool.perdisk.out.errors Counter of write errors per disk in zpool

@network.link.in.errors Number of input errors per link
Counts input errors per link
@network.link.in.packets Numbe of datagrams received by a link
@network.link.in.bytes Number of bytes received by a link
Counts number of bytes received by a link. For the physical links
this is the raw counter of bytes received, for the aggregated links
this is the number of bytes received by all links in the aggregation
group
@network.link.in.bcasts Number of broadcast datagrams received by a link
@network.link.in.mcasts Number of multicast datagrams
Counts multicast datagram recieved by a link.
@network.link.in.nobufs Number of inpit packets discared
Counts number of packets discared because of failure to allocate buffers
@network.link.out.errors Number of output errors per link
@network.link.out.packets Number of packets sent from a link
@network.link.out.bytes Number of bytes sent from a link
@network.link.out.bcasts Number of broadcast datagrams sent from a link
@network.link.out.mcasts Number of multicast datagrams sent from a link
@network.link.out.nobufs Number of output packets discared
Counts number of packets discared because of failure to allocate buffers
@network.link.collisions Number of collisions detected per link
@network.link.state Link state
1 - Link is up, 2 - Link is down, 0 - unknown state
@network.link.duplex Link duplex
1 - Half duplex, 2 - Full duplex
@network.link.speed Link speed in bytes per second
@hinv.pagesize Memory page size
The memory page size of the running kernel in bytes.
@hinv.physmem Total physical system memory
Total physical system memory size rounded down to the nearest page size
boundary
@pmda.uname identity and type of current system
Identity and type of current system.  The concatenation of the values
returned from utsname(2), also similar to uname -a.
@kernel.fsflush.scanned Number of pages scanned by fsflush daemon
@kernel.fsflush.examined Number of pages examined by fsflush daemon
@kernel.fsflush.coalesced Number of pages coalesced into larger page
@kernel.fsflush.modified Number of modified pages written to disk
@kernel.fsflush.locked Number of pages locked by fsflush daemon
Pages which were considered to be on interest for further examination
are locked before deciding if they could be coalesced, released or flushed
to disk.
@kernel.fsflush.released Number of free pages released by fsflush daemon
@kernel.fsflush.time Amount of time fsflush daemon spent doing its work
@mem.physmem Total physical system memory
Total physical system memory size rounded down to the nearest page size
boundary. This metric is the same as hinv.physmem but uses different
units.
@mem.freemem Amount of free memory in the system
@mem.lotsfree Paging theshold
If freemem fails below the lostfree threshold then paging out daemon
starts its activity. Default value for lotsfree is 1/64 of physical memory
or 512K (which ever is larger).
@mem.availrmem Amount of resident memory in the system

@kernel.all.io.bread Physical block reads across all CPUs
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.all.io.bwrite Physical block writes across all CPUs
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.all.io.lread Logical block reads across all CPUs
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.all.io.lwrite Logical block writes across all CPUs
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.all.io.phread Raw I/O reads across all CPUs
@kernel.all.io.phwrite Raw I/O writes across all CPUs
@kernel.all.io.intr Device interrupts across all CPUs

@kernel.percpu.io.bread Physical block reads
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.percpu.io.bwrite Physical block writes
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.percpu.io.lread Logical block reads
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.percpu.io.lwrite Logical block writes
This metric is only updated if reading or writing to UFS mounted filesystems,
reads and writes to ZFS do not update this metric.
@kernel.percpu.io.phread Raw I/O reads
@kernel.percpu.io.phwrite Raw I/O writes
@kernel.percpu.io.intr Device interrupts

@hinv.ncpu Number of CPUs in the system
@hinv.ndisk Number of disks in the system

@kernel.all.trap Traps across all CPUs
@kernel.all.pswitch Context switches across all CPUs
@kernel.all.syscall Total number of system calls across all CPUs
@kernel.all.sysexec Total number of calls from exec(2) family across all CPUs
@kernel.all.sysfork Total number of new processes created across all CPUs
@kernel.all.sysvfork Total number of new processes created across all CPUs
Unlike fork vfork does not copy all the virtual memory of the parent
process into the child process and is mostly used to create new system context
for execve(2). vfork(2) calls are not counted towards kernel.all.sysfork.
@kernel.all.sysread Total number of system calls from read(2) family across all CPUs
@kernel.all.syswrite Total number of system calls from write (2) family across all CPUs

@kernel.percpu.trap Traps on each CPUs
@kernel.percpu.pswitch Context switches on each CPUs
@kernel.percpu.syscall Total number of system calls on each CPU
@kernel.percpu.sysexec Total number of calls from exec(2) family on each CPU
@kernel.percpu.sysfork Total number of new processes created on each CPU
@kernel.percpu.sysvfork Total number of new processes created on each CPU
Unlike fork vfork does not copy all the virtual memory of the parent
process into the child process and is mostly used to create new system context
for execve(2). vfork(2) calls are not counted towards kernel.percpu.sysfork.
@kernel.percpu.sysread Total number of system calls from read(2) family on each CPU
@kernel.percpu.syswrite Total number of system calls from write (2) family on each CPU

@kernel.all.load Classic load avergage in 1, 5 and 15 minutes intervals

@kernel.all.cpu.wait.io	Time spent waiting for I/O across all CPUs
This metric is not updated by OpenSolaris kernel.
@kernel.all.cpu.wait.pio Time spent wait for polled I/O across all CPUs
This metric is not updated by OpenSolaris kernel.
@kernel.all.cpu.wait.swap Time spent wait for swap across all CPUs
This metric is not updated by OpenSolaris kernel.
@kernel.percpu.cpu.wait.io Time spent waiting for I/O on per-CPU basis
This metric is not updated by OpenSolaris kernel.
@kernel.percpu.cpu.wait.pio Time spent waiting for polled I/O on per-CPU basis
This metric is not updated by OpenSolaris kernel.
@kernel.percpu.cpu.wait.swap Time spent waiting swap on per-CPU basis
This metric is not updated by OpenSolaris kernel.

@zfs.arc.size Total amount of memory used by ZFS ARC
@zfs.arc.min_size Lower limit of them amount of memory for ZFS ARC
@zfs.arc.max_size Upper limit of the amount of memory for ZFS ARC
The default is to use 7/8 of total physical memory.
@zfs.arc.mru_size Amount of memory used by the most recently used pages
@zfs.arc.target_size "Ideal" size of the cached based on aging
@zfs.arc.hits.total Number of times data is found in the cache
@zfs.arc.hits.mfu Number of times data is found in the most frequently used buffers
@zfs.arc.hits.mru Number of times data is found in the most recently used buffers
@zfs.arc.hits.mfu_ghost Number of times MFU ghost buffer is accessed
A ghost buffer is a buffer which is no longer cached but is still
linked into the hash.
@zfs.arc.hits.mru_ghost Number of times MRU ghost buffer is accessed
A ghost buffer is a buffer which is no longer cached but is still
linked into the hash.
@zfs.arc.hits.demand_data Number of times file data is found in the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@zfs.arc.hits.demand_metadata Number of times filesystem metadata is found in the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@zfs.arc.hits.prefetch_data Number of times speculative request for data is satisfied from the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@zfs.arc.hits.prefetch_metadata Number of times speculative request for metadata is satisfied from the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@zfs.arc.misses.total Number of times the data is not found in the cache
@zfs.arc.misses.demand_data Number of times file data is not found in the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@zfs.arc.misses.demand_metadata Number of times filesystem metadata is not found in the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@zfs.arc.misses.prefetch_data Number of times speculatively accessed file data is not found in the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@zfs.arc.misses.prefetch_metadata Number of times speculatively accessed filesystem metadata is not found in the cache
ARC statistics provide separate counters for demand vs prefetch
and data vs metadata accesses: demand is a result of the direct
request for a particular data, prefetch is a result of speculative
request for a particular data.
@pmda.prefetch.time Amount of time spent extracting information about a group of metrics
Each metric belongs to a prefetch group. When a client asks for the metric
to be fetched the information for the group must be extracted from the kernel.
@pmda.prefetch.count Number of times each group of metrics was updated

@pmda.metric.time Amount of time spent extracting information about individual metrics
Requesting multiple instances of the same metrics counts against the metric
itself and not against the individual instances
@pmda.metric.count Number of times individual metrics have been fetched
Requesting multiple instances of the same metrics counts as multiple hits
against the metric itself

@disk.all.wait.time	Amount of time IO requests spent waiting for service
Amount of time IO transactions spent waiting to be serviced, i.e. the
transaction has been accepted for processing but for which the processing
has not yet begun. Each transaction waiting for processing adds to
to the total time which means that if multiple transactions are waiting then
total time for the sampling interval may be larger then the interval.

@disk.dev.wait.time	Amount of time IO requests spent waiting for service
Amount of time IO transactions spent waiting to be serviced, i.e. the
transaction has been accepted for processing but for which the processing
has not yet begun. Each transaction waiting for processing adds to
to the total time which means that if multiple transactions are waiting then
total time for the sampling interval may be larger then the interval.

@disk.all.wait.count	Number of transactions waiting to be serviced
Number of transactions accepted for processing but for which the processing
has not yet begun.
@disk.dev.wait.count	Number of transactions waiting to be serviced
Number of transactions accepted for processing but for which the processing
has not yet begun.

@disk.all.run.time	Amount of time spent processing IO requests
@disk.dev.run.time	Amount of time spent processing IO requests
@disk.all.run.count	Number of transactions being processed
@disk.dev.run.count	Number of transactions being processed


# from i86pc/os/cpuid.c
#                /*
#                 * 8bit APIC IDs on dual core Pentiums
#                 * look like this:
#                 *
#                 * +-----------------------+------+------+
#                 * | Physical Package ID   |  MC  |  HT  |
#                 * +-----------------------+------+------+
#                 * <------- chipid -------->
#                 * <------- coreid --------------->
#                 *                         <--- clogid -->
#                 *                         <------>
#                 *                         pkgcoreid
#                 *
#                 * Where the number of bits necessary to
#                 * represent MC and HT fields together equals
#                 * to the minimum number of bits necessary to
#                 * store the value of cpi->cpi_ncpu_per_chip.
#                 * Of those bits, the MC part uses the number
#                 * of bits necessary to store the value of
#                 * cpi->cpi_ncore_per_chip.
#                 */
#
@hinv.cpu.brand Marketing name of CPU
@hinv.cpu.clock Current CPU clock frequency
On CPUs which support dynamic clock frequency changes current clock frequency
could differ from the nominal ("maximum") clock frequency specified by
the manufacturer.
@hinv.cpu.maxclock Maximum clock frequency supported by CPU
Nominal CPU clock frequency as specified by the manufacturer.

@disk.dev.errors.soft Number of soft errors per device
@disk.dev.errors.hard Number of hard errors per device
@disk.dev.errors.transport Number of transport errors per device
@disk.dev.errors.media Number of media errors per device
@disk.dev.errors.recoverable Number of recoverable errors per device
@disk.dev.errors.notready Number of times device reported as not ready
@disk.dev.errors.nodevice Number of times device was found missing
@disk.dev.errors.badrequest Number of illegal requests per device
@disk.dev.errors.pfa Number of times failure prediction threshold has been exceeded
@hinv.disk.vendor Device Vendor
Can be reported as ATA if SATA device is behind SAS expander
@hinv.disk.product Device name
Vendor's device name (up-to 16 characters long)
@hinv.disk.revision Device Revision
@hinv.disk.serial Device Serial Number
@hinv.disk.capacity Device Capacity
For removal devices capacity of the media is reported.


# pylint: disable=too-many-public-methods, too-many-instance-attributes
# pylint: disable=too-many-arguments
'''
Performance Metrics Domain Agent exporting systemtap JSON metrics.
'''
import json
import jsonschema
from jsonschema.exceptions import ValidationError
import collections
from pcp.pmda import PMDA, pmdaMetric
import cpmapi as c_api
from pcp.pmapi import pmUnits
from ctypes import c_int, POINTER, cast
import os

class Metric(object):
    ''' Metric information class '''
    def __init__(self, name_prefix, name, cluster, idx, pmda):
        self.name = name
        self.full_name = "%s.%s" % (name_prefix, name)
        self.cluster = cluster
        self.idx = idx
        self.__pmda = pmda
        self.desc = ''
        self.type = c_api.PM_TYPE_UNKNOWN
        self.sem = c_api.PM_SEM_INSTANT
        self.pmid = None
        self.obj = None
        self.indom = None

    def create(self):
        '''
        Create the metric. Note that the metric will still need to be
        added to the PMDA.
        '''
        self.pmid = self.__pmda.pmid(self.cluster, self.idx)
        # FIXME: we'll need to handle units/scale at some point...
        if self.indom != None:
            self.obj = pmdaMetric(self.pmid, self.type, self.indom.obj,
                                  self.sem, pmUnits(0, 0, 0, 0, 0, 0))
        else:
            self.obj = pmdaMetric(self.pmid, self.type, c_api.PM_INDOM_NULL,
                                  self.sem, pmUnits(0, 0, 0, 0, 0, 0))

    # Note that you can't delete individual metrics. The
    # pmda.{clear,reset}_metrics() functions clear out *all* metrics.

class Indom(object):
    ''' Indom (instance domain) information class '''
    def __init__(self, idx, pmda):
        self.__pmda = pmda
        self.idx = idx
        self.obj = pmda.indom(self.idx)
        self.values = {}

    def add_value(self, name, value):
        ''' Add a value to the indom '''
        # PMDA.replace_indom() wants a dictionary, indexed by
        # indom string value. PMDA.replace_indom() doesn't really
        # care what is stored at that string value. We're storing the
        # array index there.
        self.values[name] = c_int(value)

    def lookup_inst(self, inst):
        ''' Lookup an array index based on the instance ID '''
        voidp = self.__pmda.inst_lookup(self.obj, inst)
        if voidp == None:
            return None
        valuep = cast(voidp, POINTER(c_int))
        return valuep.contents.value

class SystemtapModule(object):
    '''
    Systemtap Module class. Contains all metrics and data needed by a
    single systemtap module.
    '''
    def __init__(self, path, cluster, pmda):
        self.__path = path
        self.cluster = cluster
        self.__pmda = pmda
        self.__root_name = os.path.basename(path)
        self.__schema_path = "%s/schema" % path
        self.__schema = {}
        self.__data_path = "%s/data" % path
        self.__json_data = {}
        self.__metrics = {}
        self.__metric_idx = 0
        self.__indoms = {}

    def __load_json_schema(self):
        ''' Load the JSON schema file for this systemtap module. '''
        self.__schema = {}
        try:
            fobj = open(self.__schema_path)
        except IOError as error:
            self.__pmda.log("Couldn't open JSON schema file: %s"
                            % self.__schema_path)
            self.__pmda.log(error)
            return
        try:
            self.__schema = json.load(fobj,
                                      object_pairs_hook=collections.OrderedDict)
        except ValueError as error:
            self.__pmda.log("Couldn't parse JSON schema from %s"
                            % self.__schema_path)
            self.__pmda.log(error)
        fobj.close()

    def __load_json_data(self):
        ''' Load the JSON data file for this systemtap module. '''
        self.__json_data = {}
        try:
            fobj = open(self.__data_path)
        except IOError as error:
            self.__pmda.log("Couldn't open JSON data file: %s"
                            % self.__schema_path)
            self.__pmda.log(error)
            return
        try:
            self.__json_data \
                = json.load(fobj, object_pairs_hook=collections.OrderedDict)
        except ValueError as error:
            self.__pmda.log("Couldn't parse JSON data from %s"
                            % self.__schema_path)
            self.__pmda.log(error)
        fobj.close()

    def load(self):
        '''
        Load the JSON schema and data files for this systemtap module,
        then create metrics based on the JSON.
        '''
        self.__pmda.log("Loading module %s" % self.__root_name)
        self.__load_json_schema()
        self.__load_json_data()

        # Make sure the data fits the schema.
        try:
            jsonschema.validate(self.__json_data, self.__schema)
        except ValidationError as error:
            self.__pmda.log("JSON schema/data don't match")
            self.__pmda.log(error)
            self.cleanup()
            return

        # Update the indom list.
        self.__refresh_indoms()

        # Parse the schema header, creating metrics as needed.
        try:
            self.__parse_schema()
        except TypeError as error:
            self.__pmda.log("Couldn't parse JSON schema: %s" % error)

    def refresh_json_data(self):
        ''' Reload the JSON data and update indoms. '''
        # Just loading the JSON data.
        self.__load_json_data()

        # Update the indom list.
        self.__refresh_indoms()

    def cleanup(self):
        ''' Cleanup module data. '''
        self.__schema = {}
        self.__json_data = {}
        self.__metrics = {}

    def __refresh_indoms(self):
        ''' Refresh the list of indoms. '''
        # Notice we never delete indoms, we just keep adding.
        for array_name in self.__indoms.keys():
            index = 0
            try:
                # json_data['data'][array_name] is a list of
                # dictionaries.
                for item in self.__json_data['data'][array_name]:
                    self.__indoms[array_name].add_value(item['__id'], index)
                    index += 1
            except KeyError:
                continue
            self.__pmda.replace_indom(self.__indoms[array_name].obj,
                                      self.__indoms[array_name].values)

    def __add_metric(self, metric_info):
        ''' Create and add a metric to the pmda. '''
        metric_info.create()
        self.__pmda.add_metric(metric_info.full_name, metric_info.obj,
                               metric_info.desc)
        self.__metrics[metric_info.idx] = metric_info

    def __parse_array_schema(self, array_name, properties):
        ''' Parse a JSON array schema.  '''
        # First process the array schema "header" information.
        array_properties = None
        for (key, value) in properties.items():
            # 'type' (required): Sanity check it.
            if key == 'type':
                if not isinstance(value, unicode):
                    raise TypeError
                if value != 'object':
                    raise TypeError("Type attribute has unknown value '%s'"
                                    % value)
            # 'additionalProperties' (optional): Ignore it.
            elif key == "additionalProperties":
                # Do nothing.
                pass
            # 'properties' (required): Type check it and save for later.
            elif key == "properties":
                if not isinstance(value, dict):
                    raise TypeError
                array_properties = value
            # For everything else, raise an error.
            else:
                raise RuntimeError("Unknown attribute '%s'" % key)
        if not array_properties:
            raise RuntimeError("Schema has no 'properties' attribute")

        if not self.__indoms.has_key(array_name):
            # Note that we're creating an indom here, but we don't
            # know any values for it yet. We'll get those on a data
            # read.
            self.__indoms[array_name] = Indom(self.__pmda.indom_idx,
                                              self.__pmda)
            self.__pmda.indom_idx += 1

        # If we're here, we know the array "header" was
        # reasonable. Now process "properties", which is the real data
        # description.
        for (name, attributes) in array_properties.items():
            metric_info = Metric("%s.%s" % (self.__pmda.pmda_name,
                                            self.__root_name),
                                 "%s.%s" % (array_name, name), self.cluster,
                                 self.__metric_idx, self.__pmda)
            self.__metric_idx += 1
            metric_info.indom = self.__indoms[array_name]

            for (key, value) in attributes.items():
                # 'type' (required): Sanity check it and save it.
                if key == 'type':
                    if not isinstance(value, unicode):
                        raise TypeError
                    if value == 'string':
                        metric_info.type = c_api.PM_TYPE_STRING
                        metric_info.sem = c_api.PM_SEM_INSTANT
                    elif value == 'integer':
                        metric_info.type = c_api.PM_TYPE_64
                        metric_info.sem = c_api.PM_SEM_COUNTER
                    else:
                        raise \
                            TypeError("Type attribute has unknown value '%s'"
                                      % value)
                # 'description' (optional): Type check it and save it.
                elif key == 'description':
                    if not isinstance(value, unicode):
                        raise TypeError
                    metric_info.desc = value
                # 'additionalProperties' (optional): Ignore it.
                elif key == "additionalProperties":
                    # Do nothing.
                    pass
                # For everything else, raise an error.
                else:
                    raise \
                        RuntimeError("Schema for '%s' has an unknown"
                                     " attribute '%s'" % (name, key))

            # Make sure we have everything we need.
            if metric_info.type == c_api.PM_TYPE_UNKNOWN:
                raise RuntimeError("Schema for '%s' has no 'type' attribute"
                                   % name)

            # Add the metric (if it isn't our special '__id' metric).
            if name != '__id':
                self.__add_metric(metric_info)

    def __parse_schema(self):
        '''
        Go through the schema, looking for information we can use to create
        the pcp representation of the schema. Note that we don't support
        every possible JSON schema, we're looking for certain items.

        Refer to the following link for details of JSON schemas:

        <http://tools.ietf.org/html/draft-zyp-json-schema-03>
        '''

        # First process the schema "header" information.
        data_header = None
        for (key, value) in self.__schema.items():
            # 'type' (required): Just sanity check it.
            if key == "type":
                if not isinstance(value, unicode) or value != "object":
                    raise TypeError("Invalid schema header 'type' value")
            # 'title' (optional): Type check it.
            elif key == "title":
                if not isinstance(value, unicode):
                    raise TypeError("Invalid schema 'title' value")
            # 'description' (optional): Type check it.
            elif key == "description":
                if not isinstance(value, unicode):
                    raise TypeError("Invalid schema 'description' value")
            # 'additionalProperties' (optional): Ignore it.
            elif key == "additionalProperties":
                # Do nothing.
                pass
            # 'properties' (required): Type check it and save for later.
            elif key == "properties":
                if not isinstance(value, dict):
                    raise TypeError("Invalid schema 'properties' value")
                data_header = value
            # For everything else, raise an error.
            else:
                raise TypeError("Unknown attribute '%s'" % key)

        # If we're here, we know the "header" was reasonable. Now process
        # "properties", which is the data "header".
        if not data_header:
            raise TypeError("Schema has no 'properties' attribute")
        data_properties = None
        for (key, value) in data_header.items():
            # 'generation' (required): Just sanity check it.
            if key == "generation":
                if not isinstance(value, dict):
                    raise TypeError("Invalid schema 'generation' value")
            # 'data' (required): Type check it.
            elif key == "data":
                if not isinstance(value, dict) \
                   or not value.has_key("properties") \
                   or not isinstance(value["properties"], dict):
                    raise TypeError("Invalid schema 'data' value")
                data_properties = value["properties"]
            # For everything else, raise an error.
            else:
                raise TypeError("Unknown attribute '%s'" % key)

        # If we're here, we know the data "header" was reasonable. Now process
        # "properties.data.properties", which is the real data description.
        if not data_properties:
            raise TypeError("Schema has no 'properties.data.properties'"
                            " attribute")
        for (name, attributes) in data_properties.items():
            metric_info = Metric("%s.%s" % (self.__pmda.pmda_name,
                                            self.__root_name),
                                 name, self.cluster, self.__metric_idx,
                                 self.__pmda)
            self.__metric_idx += 1

            for (key, value) in attributes.items():
                # 'type' (required): Sanity check it and save it.
                if key == 'type':
                    if not isinstance(value, unicode):
                        raise TypeError("Invalid schema 'type' value")
                    if value == 'string':
                        metric_info.type = c_api.PM_TYPE_STRING
                        metric_info.sem = c_api.PM_SEM_INSTANT
                    elif value == 'integer':
                        metric_info.type = c_api.PM_TYPE_64
                        metric_info.sem = c_api.PM_SEM_COUNTER
                    elif value == 'array':
                        # For arrays, we have to create metrics for
                        # each subitem in the array, using the same
                        # indom. This happens in the 'items' handling
                        # below.
                        metric_info.type = c_api.PM_TYPE_NOSUPPORT
                    else:
                        raise \
                            TypeError("Type attribute has unknown value '%s'"
                                      % value)
                # 'description' (optional): Type check it and save it.
                elif key == 'description':
                    if not isinstance(value, unicode):
                        raise TypeError("Invalid schema 'description' value")
                    metric_info.desc = value
                # 'additionalProperties' (optional): Ignore it.
                elif key == "additionalProperties":
                    # Do nothing.
                    pass
                # 'default' (optional): Ignore it (for now).
                elif key == "default":
                    # Do nothing for now.
                    pass
                elif key == "items":
                    if metric_info.type != c_api.PM_TYPE_NOSUPPORT:
                        raise TypeError("Schema has an 'items' item"
                                        " for non-array '%s'" % name)

                    # If we're here, we're processing an array's
                    # schema. For arrays, we have to create metrics for
                    # each subitem in the array, using the same
                    # indom.
                    self.__parse_array_schema(name, value)
                # For everything else, raise an error.
                else:
                    raise TypeError("Schema for '%s' has an unknown"
                                    " attribute '%s'" % (name, key))

            # Make sure we have everything we need.
            if metric_info.type == c_api.PM_TYPE_UNKNOWN:
                raise TypeError("Schema for '%s' has no 'type' attribute"
                                % name)

            # Add the metric.
            if metric_info.type != c_api.PM_TYPE_NOSUPPORT:
                self.__add_metric(metric_info)

    def fetch(self, item, inst):
        ''' Fetch value for this item and instance.  '''
        if not self.__metrics.has_key(item):
            self.__pmda.log("Module %s has no item %d instance %d"
                            % (self.__root_name, item, inst))
            return [c_api.PM_ERR_PMID, 0]
        metric_info = self.__metrics[item]

        # Handle array metrics.
        if metric_info.indom != None:
            # Get the array index from the indom.
            array_index = metric_info.indom.lookup_inst(inst)
            if array_index == None:
                self.__pmda.log("Module %s has no indom %d"
                                % (self.__root_name, inst))
                return [c_api.PM_ERR_INST, 0]

            # Split the full name into the array name and metric
            (array, metric) = metric_info.name.split('.', 2)
            try:
                return [self.__json_data['data'][array][array_index][metric], 1]
            except KeyError:
                pass
        # Handle single-valued metrics.
        else:
            try:
                return [self.__json_data['data'][metric_info.name], 1]
            except KeyError:
                pass
        self.__pmda.log("Module %s couldn't fetch value for item %d instance %d"
                        % (self.__root_name, item, inst))
        return [c_api.PM_ERR_TYPE, 0]

    def refresh_metrics(self):
        '''
        Refresh metrics by re-adding all metrics for this module to
        the PMDA.
        '''
        for (dummy, metric) in self.__metrics.items():
            self.__pmda.add_metric(metric.full_name, metric.obj, metric.desc)

class StapJsonPMDA(PMDA):
    ''' systemtap JSON PMDA class '''
    def __init__(self, pmda_name, domain):
        self.pmda_name = pmda_name
        PMDA.__init__(self, self.pmda_name, domain)
        self.indom_idx = 0

        # cluster 0 is reserved for the static metrics
        self.cluster_idx = 1

        self.__metrics = {}
        # FIXME: python doesn't have a __pmParseDebug() wrapper. So,
        # if PCP_PYTHON_DEBUG has any value, turn debugging on.
        self.debug = os.environ.has_key('PCP_PYTHON_DEBUG')
        self.__add_static_metrics()

        # Load all the schemas and data.
        self.modules_by_root = {}
        self.modules_by_cluster = {}
        self.__load_all_json()

        self.set_fetch_callback(self.__fetch_callback)
	self.set_refresh_metrics(self.__refresh_metrics)
        if self.debug:
            self.log("__init__ finished")

    def __add_static_metrics(self):
        '''
        Create all the static metrics (not from a systemtap module).
        '''
        # Create our 'nmodules' metric.
        metric_info = Metric(self.pmda_name, 'nmodules', 0, 0, self)
        metric_info.type = c_api.PM_TYPE_64
        metric_info.sem = c_api.PM_SEM_COUNTER
        metric_info.desc = 'Number of modules'
        metric_info.create()
        self.add_metric(metric_info.full_name, metric_info.obj,
                        metric_info.desc)
        self.__metrics[metric_info.idx] = metric_info

        # Create out 'debug' metric.
        metric_info = Metric(self.pmda_name, 'debug', 0, 1, self)
        metric_info.type = c_api.PM_TYPE_64
        metric_info.sem = c_api.PM_SEM_INSTANT
        metric_info.desc = 'Debug logging state'
        metric_info.create()
        self.add_metric(metric_info.full_name, metric_info.obj,
                        metric_info.desc)
        self.__metrics[metric_info.idx] = metric_info

    def __remove_modules(self, removed_modules):
        ''' Clean up a list of removed modules. '''
        if len(removed_modules):
            for root in removed_modules:
                if self.debug:
                    self.log("Removing systemtap module '%s'"
                             % os.path.basename(root))
                self.modules_by_root[root].cleanup()
                cluster = self.modules_by_root[root].cluster
                del self.modules_by_root[root]
                del self.modules_by_cluster[cluster]

    def __load_all_json(self):
        '''
        Walk the filesystem and load the JSON schema/data for every
        module found.
        '''
        if self.debug:
            self.log("load_all_json entry")
        modules_seen = {}
        for root, dummy, files in os.walk('/proc/systemtap'):
            # Make sure we have both of the files we're looking for
            if 'schema' in files and 'data' in files:
                if not self.modules_by_root.has_key(root):
                    self.modules_by_root[root] \
                        = SystemtapModule(root, self.cluster_idx, self)
                    self.modules_by_cluster[self.cluster_idx] \
                        = self.modules_by_root[root]
                    self.cluster_idx += 1
                self.modules_by_root[root].load()
                modules_seen[root] = 1

        # Cleanup all removed modules.
        removed_modules = [k for k in self.modules_by_root \
                           if k not in modules_seen]
        self.__remove_modules(removed_modules)
        if self.debug:
            self.log("load_all_json exit")

    def __load_all_json_data(self):
        '''
        Walk the filesystem and refresh the JSON data for every module
        found.
        '''

        if self.debug:
            self.log("load_all_json_data entry")

        # FIXME: why do we need 'load_all_json()' and 'load_all_json_data()'?
        modules_seen = {}
        refresh_metrics = 0
        for root, dummy, files in os.walk('/proc/systemtap'):
            # Make sure we have both of the files we're looking for
            if 'schema' in files and 'data' in files:
                if not self.modules_by_root.has_key(root):
                    self.modules_by_root[root] \
                        = SystemtapModule(root, self.cluster_idx, self)
                    self.modules_by_cluster[self.cluster_idx] \
                        = self.modules_by_root[root]
                    self.cluster_idx += 1
                    self.modules_by_root[root].load()
                    if self.debug:
                        self.log("load_all_json_data: adding module '%s'" % root)
                else:
                    self.modules_by_root[root].refresh_json_data()
                modules_seen[root] = 1

        # Cleanup all removed modules.
        removed_modules = [k for k in self.modules_by_root \
                           if k not in modules_seen]
        if len(removed_modules) > 0:
            if self.debug:
                self.log("load_all_json_data: removed modules found")
            refresh_metrics = 1
            self.__remove_modules(removed_modules)

        # If we've got a new or removed module, we need to recreate
        # the metrics.
        if refresh_metrics == 1:
            if self.debug:
                self.log("*** refreshing metrics ***")
            self.clear_metrics()

            # First refresh static metrics.
            for (dummy, metric) in self.__metrics.items():
                self.add_metric(metric.full_name, metric.obj, metric.desc)

            # Now ask each systemtap module to refresh its metrics.
            for (root, module) in self.modules_by_root.items():
                module.refresh_metrics()

        if self.debug:
            self.log("load_all_json_data exit")

    def __refresh_metrics(self):
        '''
        Called before callbacks. This allows us to update the list of
        metrics if needed.
        '''
        if self.debug:
            self.log("__refresh_metrics entry")
        self.__load_all_json_data()
        if self.debug:
            self.log("__refresh_metrics exit")
	return

    def __fetch_callback(self, cluster, item, inst):
        '''
        Main fetch callback. Returns a list of value,status (single
        pair) for requested pmid/inst.
        '''
        if self.debug:
            self.log("**** fetch_callback: %d, %d, %d ****" %
                     (cluster, item, inst))
        if not self.modules_by_cluster.has_key(cluster):
            # Handle our static metrics.
            if cluster == 0:
                if item == 0:
                    return [len(self.modules_by_cluster), 1]
                elif item == 1:
                    return [self.debug, 1]
            if self.debug:
                self.log("Invalid cluster %d" % cluster)
            return [c_api.PM_ERR_PMID, 0]
        module = self.modules_by_cluster[cluster]
        return module.fetch(item, inst)

if __name__ == '__main__':
    #os.environ["PCP_PYTHON_DEBUG"] = "ALL"
    #os.environ["PCP_PYTHON_DEBUG"] = "APPL0|LIBPMDA"
    StapJsonPMDA('stap_json', 132).run()
